#!/usr/bin/python
# Copyright (c) 2022 Cohesity Inc


from __future__ import absolute_import, division, print_function

__metaclass__ = type

# GNU General Public License v3.0+ (see https://www.gnu.org/licenses/gpl-3.0.txt)


DOCUMENTATION = """
---
author: Naveena (@naveena-maplelabs)
description:
  - Ansible Module used to register, remove, start, and stop the Cohesity
    Protection Job on a Cohesity Cluster.
  - When executed in a playbook, the Cohesity Protection Job will be validated
    and the appropriate state action
  - will be applied.
module: cohesity_job
options:
  append_to_existing:
    default: false
    description:
      - Specifies when job is already available and new list of virtual machines
        needs to be added to existing list.
      - If not specified new list of vms will replace the existing vms available
        in the Protection job.
      - In case of tag based jobs, if append_to_existing is set to true new list
        of tags will be added to already available tags.
      - Optional and only valid when (environment=VMware)
    type: bool
  cancel_active:
    default: false
    description:
      - Specifies if Current Running Backup Job should be canceled.  If False,
        active jobs will not be stopped
      - and a failure will be raised.
      - Optional and only valid when I(state=stopped)
    type: bool
  cluster:
    aliases:
      - cohesity_server
    description:
      - IP or FQDN for the Cohesity Cluster
    type: str
  cohesity_admin:
    aliases:
      - admin_name
      - cohesity_user
      - username
    description:
      - Username with which Ansible will connect to the Cohesity Cluster. Domain
        Specific credentails can be configured in following formats
      - AD.domain.com/username
      - AD.domain.com/username@tenant
      - LOCAL/username@tenant
    type: str
  cohesity_password:
    aliases:
      - password
      - admin_pass
    description:
      - Password belonging to the selected Username.  This parameter will not be
        logged.
    type: str
  delete_backups:
    default: false
    description:
      - Specifies if Snapshots generated by the Protection Job should also be
        deleted when the Job is deleted.
      - Optional and only valid when I(state=absent)
    type: bool
  delete_sources:
    default: false
    description:
      - Specifies job is already available, if source available in Protection
        Job needs to be removed.
      - Optional and only valid when (environment=Physical, PhysicalFiles,
        GenericNas)
    type: bool
  delete_vms:
    description:
      - Applicable only when job is already available
      - List of virtual machines will be removed from the job.
      - Optional and only valid when (environment=VMware)
    type: list
    elements: str
  description:
    description:
      - Optional Description to assign to the Protection Job
    type: str
    default: ""
  disable_indexing:
    default: false
    description: Enabling this will disable indexing while creating/updating the
      backup jobs.
    type: bool
  environment:
    choices:
      - VMware
      - View
      - Physical
      - PhysicalFiles
      - GenericNas
    default: PhysicalFiles
    description:
      - Specifies the environment type (such as VMware or SQL) of the Protection
        Source this Job
      - is protecting. Supported environment types include 'PhysicalFiles',
        'VMware'
    required: false
    type: str
  exclude:
    description:
      - Specifies the list of VMs to be exclude.
      - Applicable only when environment is set to VMware.
    elements: str
    type: list
    default: []
  exclude_tags:
    description:
      - Specifies the list of VMware tags to be exclude.
      - Applicable only when environment is set to VMware.
      - Yet to be implemented.
    type: list
    default: []
    elements: dict
  include:
    description:
      - Specifies the list of VMs to be included.
      - Applicable only when environment is set to VMware.
    elements: str
    type: list
    default: []
  include_tags:
    description:
      - Specifies the list of VMware tags to be included.
      - List of objects with category name as key and user tags as list should
        be provided
      - Applicable only when environment is set to VMware.
    type: list
    default: []
    elements: dict
  indexing:
    description:
      - Specifies the list of allowed and denied indexing prefixes
      - Applicable only when disable_indexing is set to false.
      - allowed_prefix contains list of prefixes to be allowed while indexing.
      - denied_prefix contains list of prefixes to be denied while indexing.
    type: dict
    default: {}
  name:
    aliases:
      - job_name
    description:
      - Name to assign to the Protection Job
    required: true
    type: str
  ondemand_run_type:
    choices:
      - Regular
      - Full
      - Log
      - System
    default: Regular
    description:
      - Specifies the type of OnDemand Backup.
    type: str
  protection_policy:
    aliases:
      - policy
    default: Bronze
    description:
      - Valid policy name or ID for andexisting Protection Policy to be assigned
        to the job.
      - Required when I(state=present).
    type: str
  protection_sources:
    aliases:
      - sources
    default: []
    description:
      - A list of dictionaries with endpoints and paths to backup. Required when
        I(state=present).
      - (valid only for physical sources and file based protection jobs)
      - protection_sources contains list of dicts(endpoint(str), paths(dict))
      - excludeFilePaths - (List, defaults to empty list [], optional field) -
        String
      - includeFilePath  - (String, default / for linux machines, required field
        for windows machines)
      - skipNestedVolumes - True (Boolean, defaults to True)
    elements: dict
    type: list
  start_time:
    description:
      - Specifies the registered start time for the Protection Job.  Format must
        be 24hr time in either HHMM or HH:MM style.
      - If not configured then the Cluster will automatically select a time.
    type: str
    default: ""
  state:
    choices:
      - present
      - absent
      - started
      - stopped
    default: present
    description:
      - Determines the state of the Protection Job
    type: str
  storage_domain:
    default: DefaultStorageDomain
    description:
      - Existing Storage Domain to which the Protection Job will be associated.
        Required when I(state=present).
    type: str
  time_zone:
    default: America/Los_Angeles
    description:
      - Specifies the timezone to use when calculating time for this Protection
        Job such as the Job start time.
    type: str
  validate_certs:
    default: false
    description:
      - Switch determines if SSL Validation should be enabled.
    type: bool
    aliases:
      - cohesity_validate_certs
  view_name:
    description:
      - Specifies the name of view to be protected.
      - Required when environment is set to View.
    type: str
extends_documentation_fragment:
- cohesity.dataprotect.cohesity
short_description: "Management of Cohesity Protection Jobs"
version_added: 1.3.0
"""

EXAMPLES = """
# Create a new Physical Server Protection Job
- cohesity_job:
    cluster: cohesity.lab
    username: admin
    password: password
    state: present
    name: myhost
    environment: PhysicalFiles
    protection_sources:
      - myhost.domain.lab
    protection_policy: Bronze
    storage_domain: Default

# Create a new VMware Server Protection Job
- cohesity_job:
    cluster: cohesity.lab
    username: admin
    password: password
    state: present
    name: myvcenter
    environment: VMware
    protection_sources:
      - myvcenter.domain.lab
    protection_policy: Gold
    storage_domain: Default

# Remove an existing VMware Server Protection Job
- cohesity_job:
    cluster: cohesity.lab
    username: admin
    password: password
    state: absent
    name: myvcenter
    environment: VMware

# Remove an existing VMware Server Protection Job and remove all Backups
- cohesity_job:
    cluster: cohesity.lab
    username: admin
    password: password
    state: absent
    name: myvcenter
    environment: VMware
    delete_backups: true

# Start an existing VMware Server Protection Job
- cohesity_job:
    cluster: cohesity.lab
    username: admin
    password: password
    state: started
    name: myvcenter
    environment: VMware

# Stop an actively running VMware Server Protection Job
- cohesity_job:
    cluster: cohesity.lab
    username: admin
    password: password
    state: stopped
    name: myvcenter
    environment: VMware
"""

RETURN = """
# Returns the registered Protection Job ID
"""

import json
import time
from collections import defaultdict
from ansible.module_utils.basic import AnsibleModule
from ansible.module_utils.urls import open_url
try:
    from urllib import error as urllib_error
except ImportError:
    from ansible.module_utils.urls import urllib_error

try:
    # => When unit testing, we need to look in the correct location however, when run via ansible,
    # => the expectation is that the modules will live under ansible.
    from ansible_collections.cohesity.dataprotect.plugins.module_utils.cohesity_auth import (
        get__cohesity_auth__token,
    )
    from ansible_collections.cohesity.dataprotect.plugins.module_utils.cohesity_utilities import (
        cohesity_common_argument_spec,
        raise__cohesity_exception__handler,
        REQUEST_TIMEOUT,
    )
    from ansible_collections.cohesity.dataprotect.plugins.module_utils.cohesity_hints import (
        check_source_reachability,
        get__prot_source_id__by_endpoint,
        get__prot_source_root_id__by_environment,
        get__prot_policy_id__by_name,
        get__storage_domain_id__by_name,
        get__protection_jobs__by_environment,
        get__protection_run__all__by_id,
        get_cohesity_client,
    )
    from ansible_collections.cohesity.dataprotect.plugins.module_utils.cohesity_constants import (
        RELEASE_VERSION,
    )
except Exception:
    pass


class ParameterViolation(Exception):
    pass


class ProtectionException(Exception):
    pass


def check__mandatory__params(module):
    # => This method will perform validations of optionally mandatory parameters
    # => required for specific states and environments.
    success = True
    missing_params = list()
    environment = module.params.get("environment")

    if module.params.get("state") == "present":
        action = "creation"

        if not module.params.get("protection_sources"):
            success = False
            missing_params.append("protection_sources")
        if not module.params.get("protection_policy"):
            success = False
            missing_params.append("protection_policy")
        if not module.params.get("storage_domain"):
            success = False
            missing_params.append("storage_domain")

    else:
        action = "remove"

    if not success:
        module.fail_json(
            msg="The following variables are mandatory for this action ("
            + action
            + ") when working with environment type ("
            + environment
            + ")",
            missing=missing_params,
        )


def check__protection_job__exists(module, self):
    try:
        job_list = get__protection_jobs__by_environment(module, self)

        for job in job_list:
            if job["name"] == self["name"]:
                return job["id"], job

        return False, ""
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def wait__for_job_state__transition(module, self, job_runs, state="start"):
    if not job_runs:
        job_runs = []
    if state != "start":
        state = "stop"

    loop_cnt = 0
    while loop_cnt <= 20:
        payload = self.copy()
        # => If the backup finishes before we check, we need to look
        # => at previous backups to see if the last job is successful.
        payload["active_only"] = False
        # if state == "stop":
        #     # => If we are checking to see if the job is stopped, then
        #     # => Simply filtering out the active jobs will suffice.
        #     payload["active_only"] = True
        payload["is_deleted"] = False
        for job_run in job_runs:
            currently_active = get__protection_run__all__by_id(module, payload)
            if not currently_active:
                continue
            status = currently_active[0]["backupRun"]["status"].lstrip("k")
            if state == "start":
                if currently_active:
                    valid_states = ["Accepted", "Success", "Running"]
                    for check_state in valid_states:
                        if status == check_state:
                            try:
                                job_runs.pop(job_run)
                            except Exception:
                                if len(job_runs) == 1:
                                    job_runs = []
            else:
                if status == "Canceled" and job_run in job_runs:
                    job_runs.pop(job_runs.index(job_run))
            if not job_runs:
                break
        if job_runs:
            time.sleep(5)
            loop_cnt += 1
        else:
            break

    if job_runs:
        module.fail_json(
            msg="Failed to successfully " + state + " the Cohesity Protection Job",
            changed=False,
            id=self["id"],
            loop_cnt=loop_cnt,
        )


def convert_windows_file_paths(path):
    if ":" in path:
        path_structure = path.split(":")
        path = "/" + path_structure[0] + path_structure[1]
        for char in ("\\\\", "\\"):
            path = path.replace(char, "/")
    return path


def create_paths_parameter(module, update_source_ids):
    sources_with_paths = []
    for source in module.params.get("protection_sources"):
        if (source["endpoint"] is not None) and source["endpoint"] in update_source_ids:
            source_paths = {}
            source_paths["sourceId"] = source["endpoint"]
            source_paths["physicalSpecialParameters"] = {}
            if "paths" in source:
                source_paths["physicalSpecialParameters"]["filepaths"] = []
                for path in source["paths"]:
                    t = {}
                    t.setdefault("backupFilePath", "/")
                    t.setdefault("excludedFilePaths", [])
                    t.setdefault("skipNestedVolumes", True)
                    if "includeFilePath" in path:
                        t["backupFilePath"] = convert_windows_file_paths(
                            path["includeFilePath"]
                        )
                    if "excludeFilePaths" in path:
                        files = []
                        for file in path["excludeFilePaths"]:
                            files.append(convert_windows_file_paths(file))
                        t["excludedFilePaths"] = files
                    if "skipNestedVolumes" in path:
                        t["skipNestedVolumes"] = path["skipNestedVolumes"]

                    source_paths["physicalSpecialParameters"]["filepaths"].append(t)
            else:
                source_paths["physicalSpecialParameters"] = {
                    "filePaths": [{"backupFilePath": "/", "skipNestedVolumes": True}]
                }
            sources_with_paths.append(source_paths)
    return sources_with_paths


def parse_vmware_protection_sources_json(response, vm_names):
    ids = []
    nodes = []
    for node in response:
        if "nodes" in node:
            nodes.append(node["nodes"])
        if ("protectionSource" in node) and (
            node["protectionSource"]["name"] in vm_names
        ):
            ids.append(node["protectionSource"]["id"])

    while len(nodes) != 0:
        objects = nodes.pop()
        for node in objects:
            if "nodes" in node:
                nodes.append(node["nodes"])
            if ("protectionSource" in node) and (
                node["protectionSource"]["name"] in vm_names
            ):
                ids.append(node["protectionSource"]["id"])
    return list(set(ids))


def find_tag_id(module, nodes, tags):
    """
    Function to return list of tag ids filtered by category and tag name.
    """
    ids = []
    for node in nodes:
        if "protectionSource" in node:
            vmware_source = node["protectionSource"]["vmWareProtectionSource"]
            if vmware_source["type"] != "kTagCategory" and "nodes" in node:
                nodes.extend(node["nodes"])
                continue

            if (
                vmware_source["type"] == "kTagCategory"
                and vmware_source["name"] not in tags
            ):
                continue
            category_name = vmware_source["name"]
            for item in node.get("nodes", []):
                vmware_source = item["protectionSource"]["vmWareProtectionSource"]
                if (
                    vmware_source["type"] == "kTag"
                    and vmware_source["name"] not in tags[category_name]
                ):
                    continue
                ids.append(item["protectionSource"]["id"])
    return list(ids)


def _get_tag_ids(module, tags, parentSourceId):
    """
    Function to fetch VMware tag ids for list of tag names.
    """
    try:
        if not client:
            module.fail_json(
                msg="Error while creating cohesity client, err msg '%s'" % client,
                changed=False,
            )
        result = client.protection_sources.list_protection_sources(
            id=parentSourceId,
            exclude_types=[
                "kDatacenter",
                "kComputeResource",
                "kResourcePool",
                "kDatastore",
                "kHostSystem",
                "kVirtualMachine",
            ],
        )
        if not result or not result[0].nodes:
            module.fail_json(
                msg="Failed to fetch tags for source with id " + str(parentSourceId),
                changed=False,
            )
        nodes = result[0].nodes
        return find_tag_id(module, nodes, tags)
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def get_vmware_ids(module, job_meta_data, job_details, vm_names):
    server = module.params.get("cluster")
    validate_certs = module.params.get("validate_certs")
    token = job_details["token"]
    try:
        uri = (
            "https://"
            + server
            + "/irisservices/api/v1/public/protectionSources?id="
            + str(job_meta_data["parentSourceId"])
        )
        headers = {
            "Accept": "application/json",
            "Authorization": "Bearer " + token,
            "user-agent": "cohesity-ansible/v{}".format(RELEASE_VERSION),
        }
        response = open_url(
            url=uri,
            method="GET",
            headers=headers,
            validate_certs=validate_certs,
            timeout=REQUEST_TIMEOUT,
        )

        if not response.getcode() == 200:
            raise ProtectionException(
                msg="Failed to get VMware protection source details"
            )
        response = json.loads(response.read())
        ids = parse_vmware_protection_sources_json(response, vm_names)
        return ids
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def get_vmware_vm_ids(module, job_meta_data, job_details, vm_names):
    server = module.params.get("cluster")
    validate_certs = module.params.get("validate_certs")
    token = job_details["token"]
    try:
        uri = (
            "https://"
            + server
            + "/irisservices/api/v1/public/protectionSources/virtualMachines?vCenterId="
            + str(job_meta_data["parentSourceId"])
        )
        headers = {
            "Accept": "application/json",
            "Authorization": "Bearer " + token,
            "user-agent": "cohesity-ansible/v{}".format(RELEASE_VERSION),
        }
        response = open_url(
            url=uri,
            method="GET",
            headers=headers,
            validate_certs=validate_certs,
            timeout=REQUEST_TIMEOUT,
        )

        if not response.getcode() == 200:
            raise ProtectionException(
                msg="Failed to get VMware protection source details"
            )
        response = json.loads(response.read())
        vm_ids = []
        vm_names_lowercase = [v.lower() for v in vm_names]
        for vm in response:
            if vm["name"].lower() in vm_names_lowercase:
                vm_ids.append(vm["id"])
        return vm_ids

    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def get_view_storage_domain_id(module, self):
    """
    function to get view's storage domain id.
    :param module:
    :param self:
    :return:
    """
    server = module.params.get("cluster")
    validate_certs = module.params.get("validate_certs")
    token = self["token"]
    view_name = module.params.get("view_name")
    try:
        uri = "https://" + server + "/irisservices/api/v1/public/views/" + view_name
        headers = {
            "Accept": "application/json",
            "Authorization": "Bearer " + token,
            "user-agent": "cohesity-ansible/v{}".format(RELEASE_VERSION),
        }
        response = open_url(
            url=uri,
            method="GET",
            headers=headers,
            validate_certs=validate_certs,
            timeout=REQUEST_TIMEOUT,
        )
        response = json.loads(response.read())
        return response["viewBoxId"]
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def update_indexing(module, payload):
    """
    Function to update indexing values in the payload.
    """
    payload["indexingPolicy"] = {
        "disableIndexing": module.params.get("disable_indexing"),
        "allowPrefixes": ["/"],
        "denyPrefixes": [
            "/$Recycle.Bin",
            "/Windows",
            "/Program Files",
            "/ProgramData",
            "/System Volume Information",
            "/Users/*/AppData",
            "/Recovery",
            "/Program Files (x86)",
            "/var",
            "/usr",
            "/sys",
            "/proc",
            "/lib",
            "/grub",
            "/grub2",
            "/opt",
            "/splunk",
        ],
    }
    if module.params.get("indexing").get("allowed_prefix", None):
        payload["indexingPolicy"]["allowPrefixes"] = module.params.get("indexing")[
            "allowed_prefix"
        ]
    if module.params.get("indexing").get("denied_prefix", None):
        payload["indexingPolicy"]["denyPrefixes"] = module.params.get("indexing")[
            "denied_prefix"
        ]
    return payload


def register_job(module, self):
    server = module.params.get("cluster")
    validate_certs = module.params.get("validate_certs")
    token = self["token"]
    try:
        uri = "https://" + server + "/irisservices/api/v1/public/protectionJobs"
        headers = {
            "Accept": "application/json",
            "Authorization": "Bearer " + token,
            "user-agent": "cohesity-ansible/v{}".format(RELEASE_VERSION),
        }
        payload = self.copy()

        # => Remove the Authorization Token from the Payload
        payload.pop("token", None)

        payload["environment"] = "k" + self["environment"]
        payload["timezone"] = self["timezone"]
        update_indexing(module, payload)
        if payload["environment"] == "kPhysicalFiles":
            payload["sourceSpecialParameters"] = create_paths_parameter(
                module, payload["sourceIds"]
            )
        elif payload["environment"] == "kVMware":
            parent_source_id = {"parentSourceId": self["parentSourceId"]}
            if module.params.get("include_tags"):
                payload["vmTagIds"] = []
                tags = module.params.get("include_tags")
                for include_tags in tags:
                    tag_ids = _get_tag_ids(module, include_tags, self["parentSourceId"])
                    if tag_ids:
                        payload["vmTagIds"].append(tag_ids)
                if payload.get("sourceIds"):
                    del payload["sourceIds"]
            if module.params.get("exclude_tags"):
                payload["excludeVmTagIds"] = []
                tags = module.params.get("exclude_tags")
                for exclude_tags in tags:
                    tag_ids = _get_tag_ids(module, exclude_tags, self["parentSourceId"])
                    if tag_ids:
                        payload["excludeVmTagIds"].append(tag_ids)
            if len(module.params.get("include")) != 0:
                vms = module.params.get("include")
                payload["sourceIds"] = get_vmware_ids(
                    module, parent_source_id, self, vms
                )
            if len(module.params.get("exclude")) != 0:
                vms = module.params.get("exclude")
                payload["excludeSourceIds"] = get_vmware_ids(
                    module, parent_source_id, self, vms
                )
        data = json.dumps(payload)
        response = open_url(
            url=uri,
            data=data,
            headers=headers,
            validate_certs=validate_certs,
            timeout=REQUEST_TIMEOUT,
        )

        response = json.loads(response.read())

        # => This dictionary will allow us to return a standardized output
        # => for all Protection Job.
        output = dict(
            id=response["id"],
            name=response["name"],
            environment=response["environment"].lstrip("k"),
            priority=response["priority"].lstrip("k"),
            start_time=response["startTime"],
        )

        return output
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def start_job(module, self):
    server = module.params.get("cluster")
    validate_certs = module.params.get("validate_certs")
    token = self["token"]

    payload = self.copy()
    payload["active_only"] = True
    payload["is_deleted"] = False
    currently_active = get__protection_run__all__by_id(module, payload)
    if currently_active:
        results = dict(
            changed=False,
            msg="The Protection Job for this host is currently running",
            name=module.params.get("name"),
        )
        module.exit_json(**results)
    if module.check_mode:
        results = dict(
            changed=True,
            msg="Check Mode: This action will start the Protection Job.",
            name=module.params.get("name"),
        )
        module.exit_json(**results)

    try:
        uri = (
            "https://"
            + server
            + "/irisservices/api/v1/public/protectionJobs/run/"
            + str(self["id"])
        )
        headers = {
            "Accept": "application/json",
            "Authorization": "Bearer " + token,
            "user-agent": "cohesity-ansible/v{}".format(RELEASE_VERSION),
        }
        source_ids = payload.get("sourceIds", [])
        payload = dict()
        payload["runNowParameters"] = [
            {"sourceId": source_id} for source_id in source_ids
        ]
        payload["name"] = self["name"]
        payload["environment"] = self["environment"]

        payload["runType"] = "k" + self["runType"]

        data = json.dumps(payload)
        response = open_url(
            url=uri,
            data=data,
            headers=headers,
            validate_certs=validate_certs,
            timeout=REQUEST_TIMEOUT,
        )
        # => There is no data output so if we get a 204 then we are
        # => happy.
        if not response.getcode() == 204:
            raise ProtectionException(
                msg="Something went wrong with the attempt to start protection job %s"
                % self["id"]
            )

        # => This dictionary will allow us to return a standardized output
        # => for all Protection Job.
        output = dict(id=self["id"])

        # => It can take a few moments for the job to actually stop.  In this case,
        # => We will introduce a delay and check every (5) seconds for up to a minute
        # => to see if the job stopped.
        wait__for_job_state__transition(module, self, [self["id"]], state="start")

        return output
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def update_job(module, job_details, update_source_ids=None):
    server = module.params.get("cluster")
    validate_certs = module.params.get("validate_certs")
    token = job_details["token"]
    try:
        uri = (
            "https://"
            + server
            + "/irisservices/api/v1/public/protectionJobs/"
            + str(job_details["id"])
        )
        headers = {
            "Accept": "application/json",
            "Authorization": "Bearer " + token,
            "user-agent": "cohesity-ansible/v{}".format(RELEASE_VERSION),
        }
        payload = job_details.copy()
        del payload["token"]
        if (
            module.params.get("environment") == "PhysicalFiles"
            and module.params.get("delete_sources") is False
        ):
            if "sourceSpecialParameters" in payload:
                updated_source_params = []
                for parameter in payload["sourceSpecialParameters"]:
                    if parameter["sourceId"] not in update_source_ids:
                        updated_source_params.append(parameter)
                payload["sourceSpecialParameters"] = updated_source_params
            if module.params.get("state") == "present":
                payload["sourceSpecialParameters"].extend(
                    create_paths_parameter(module, update_source_ids)
                )
        data = json.dumps(payload)
        response = open_url(
            url=uri,
            data=data,
            headers=headers,
            validate_certs=validate_certs,
            method="PUT",
            timeout=REQUEST_TIMEOUT,
        )
        if not response.getcode() == 200:
            raise ProtectionException(
                msg="Something went wrong with the attempt to get protection job %s"
                % job_details["id"]
            )

        response = json.loads(response.read())
        output = dict(
            id=response["id"],
            name=response["name"],
            environment=response["environment"].lstrip("k"),
        )
        return output
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def get_prot_job_details(self, module):
    server = module.params.get("cluster")
    validate_certs = module.params.get("validate_certs")
    token = self["token"]
    try:
        uri = (
            "https://"
            + server
            + "/irisservices/api/v1/public/protectionJobs/"
            + str(self["id"])
        )

        headers = {
            "Accept": "application/json",
            "Authorization": "Bearer " + token,
            "user-agent": "cohesity-ansible/v{}".format(RELEASE_VERSION),
        }
        response = open_url(
            url=uri,
            headers=headers,
            validate_certs=validate_certs,
            timeout=REQUEST_TIMEOUT,
        )
        if not response.getcode() == 200:
            raise ProtectionException(
                msg="Something went wrong with the attempt to get protection job %s"
                % self["id"]
            )

        output = json.loads(response.read())
        return output
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def stop_job(module, self):
    server = module.params.get("cluster")
    validate_certs = module.params.get("validate_certs")
    token = self["token"]

    payload = self.copy()
    payload["active_only"] = True
    payload["is_deleted"] = False
    currently_active = get__protection_run__all__by_id(module, payload)
    if not currently_active:
        results = dict(
            changed=False,
            msg="The Protection Job for this host is not currently running",
            name=module.params.get("name"),
        )
        module.exit_json(**results)
    if not module.params.get("cancel_active") and currently_active:
        module.fail_json(
            changed=False,
            msg="The Protection Job for this host is active and cannot be stopped",
        )
    if module.check_mode and module.params.get("cancel_active"):
        results = dict(
            changed=False,
            msg="Check Mode: The Protection Job for this host is currently running and will be cancelled",
            name=module.params.get("name"),
        )
        module.exit_json(**results)
    try:
        uri = (
            "https://"
            + server
            + "/irisservices/api/v1/public/protectionRuns/cancel/"
            + str(self["id"])
        )
        headers = {
            "Accept": "application/json",
            "Authorization": "Bearer " + token,
            "user-agent": "cohesity-ansible/v{}".format(RELEASE_VERSION),
        }
        payload = self.copy()

        # => Remove the Authorization Token from the Payload
        payload.pop("token", None)

        output = dict(
            id=self["id"],
            cancel_active=module.params.get("cancel_active"),
            jobRunIds=list(),
        )
        for backup_run in currently_active:
            payload["jobRunId"] = backup_run["backupRun"]["jobRunId"]

            data = json.dumps(payload)
            response = open_url(
                url=uri,
                data=data,
                headers=headers,
                validate_certs=validate_certs,
                timeout=REQUEST_TIMEOUT,
            )

            # => There is no data output so if we get a 204 then we are
            # => happy.
            if not response.getcode() == 204:
                raise ProtectionException(
                    msg="Something went wrong with the attempt to cancel protection job %s"
                    % str(self["id"])
                )

            # => This dictionary will allow us to return a standardized output
            # => for all Protection Job.

            output["jobRunIds"].append(payload["jobRunId"])

        # => It can take a few moments for the job to actually stop.  In this case,
        # => We will introduce a delay and check every (5) seconds for up to a minute
        # => to see if the job stopped.
        wait__for_job_state__transition(module, self, output["jobRunIds"], state="stop")

        return output
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def unregister_job(module, self):
    server = module.params.get("cluster")
    validate_certs = module.params.get("validate_certs")
    token = self["token"]
    try:
        uri = (
            "https://"
            + server
            + "/irisservices/api/v1/public/protectionJobs/"
            + str(self["id"])
        )
        headers = {
            "Accept": "application/json",
            "Authorization": "Bearer " + token,
            "user-agent": "cohesity-ansible/v{}".format(RELEASE_VERSION),
        }

        payload = dict(deleteSnapshots=self["deleteSnapshots"])
        data = json.dumps(payload)

        response = open_url(
            url=uri,
            method="DELETE",
            data=data,
            headers=headers,
            validate_certs=validate_certs,
            timeout=REQUEST_TIMEOUT,
        )

        return response
    except urllib_error.URLError as e:
        # => Capture and report any error messages.
        raise__cohesity_exception__handler(e.read(), module)
    except Exception as error:
        raise__cohesity_exception__handler(error, module)


def check_default_fields(module, job_meta_data, job_details):
    """
    Function to check if any default backup job is updated.
    returns the status.
    """
    status = False
    # Check the start time of the backup job.
    if module.params.get("start_time"):
        start_time = module.params.get("start_time").replace(":", "")
        if not len(start_time) == 4:
            # => There are only so many options here but if we get more characters
            # => than four then we need to escape quickly.
            module.fail_json(
                msg="Invalid start_time selected ("
                + module.params.get("start_time")
                + ").  Please review and submit the correct Protection Job Starting time."
            )
        start_time = dict(
            hour=int(start_time[0] + start_time[1]),
            minute=int(start_time[2] + start_time[3]),
        )
        existing_start_time = dict(
            hour=job_meta_data["startTime"]["hour"],
            minute=job_meta_data["startTime"]["minute"],
        )
        if start_time != existing_start_time:
            status = True
            job_meta_data["startTime"] = start_time
    if job_meta_data["timezone"] != module.params.get("time_zone"):
        status = True
        job_meta_data["timezone"] = module.params.get("time_zone")
    policy_id = get__prot_policy_id__by_name(module, job_details)
    if policy_id != job_meta_data["policyId"]:
        status = True
        job_meta_data["policyId"] = policy_id
    return status


def update_vmware_job(module, job_meta_data, job_details):
    delete_vm_ids = []
    avl_source_ids = job_meta_data.get("sourceIds", [])
    avl_exclude_source_ids = job_meta_data.get("excludeSourceIds", [])
    # Check for start time, timezone, policy and storage domain.
    status = check_default_fields(module, job_meta_data, job_details)
    job_meta_data["token"] = job_details["token"]

    if (
        len(module.params.get("exclude")) != 0
        or len(module.params.get("include")) != 0
        or len(module.params.get("include_tags")) != 0
        or module.params.get("delete_vms")
    ):
        existing_include_tags = job_meta_data.get("vmTagIds", [])
        existing_include_tags.sort()
        existing_exclude_tags = job_meta_data.get("excludeVmTagIds", [])
        existing_exclude_tags.sort()
        job_meta_data["vmTagIds"] = []
        job_meta_data["excludeVmTagIds"] = []
        tags = module.params.get("include_tags")
        if module.params.get("include_tags"):
            for include_tags in tags:
                tag_ids = _get_tag_ids(
                    module, include_tags, job_meta_data["parentSourceId"]
                )
                if tag_ids:
                    job_meta_data["vmTagIds"].append(tag_ids)
        if module.params.get("exclude_tags"):
            for exclude_tags in module.params.get("exclude_tags"):
                tag_ids = _get_tag_ids(
                    module, exclude_tags, job_meta_data["parentSourceId"]
                )
                if tag_ids:
                    job_meta_data["excludeVmTagIds"].append(tag_ids)
        if module.params.get("append_to_existing"):
            for list_item in existing_include_tags:
                if list_item not in job_meta_data["vmTagIds"]:
                    job_meta_data["vmTagIds"].append(list_item)
        job_meta_data["vmTagIds"].sort()
        if len(module.params.get("exclude")) != 0:
            vms = module.params.get("exclude")
            exclude_vm_ids = get_vmware_ids(module, job_meta_data, job_details, vms)
            job_meta_data["excludeSourceIds"] = exclude_vm_ids
        if len(module.params.get("include")) != 0:
            vms = module.params.get("include")
            include_vm_ids = get_vmware_ids(module, job_meta_data, job_details, vms)
            append_to_existing = module.params.get("append_to_existing")
            # If append_to_existing is set to true, then job sources are replaced with
            # latest include vms, if append_to_existing is set to false latest include
            # vms are added to existing vms.
            if append_to_existing:
                existing_source_ids = job_meta_data["sourceIds"]
                include_vm_ids.extend(
                    [
                        source_id
                        for source_id in existing_source_ids
                        if source_id not in include_vm_ids
                    ]
                )
            job_meta_data["sourceIds"] = include_vm_ids
        if module.params.get("delete_vms"):
            delete_vm_ids = get_vmware_ids(
                module, job_meta_data, job_details, module.params.get("delete_vms")
            )
            if delete_vm_ids:
                # Remove the list of vm ids from the sourceId list.
                job_meta_data["sourceIds"] = list(
                    set(job_meta_data.get("sourceIds", [])) - set(delete_vm_ids)
                )
        if (
            not status
            and (set(job_meta_data.get("sourceIds", [])) == set(avl_source_ids))
            and (
                set(avl_exclude_source_ids)
                == set(job_meta_data.get("excludeSourceIds", []))
            )
            and existing_include_tags == job_meta_data["vmTagIds"]
            and existing_exclude_tags == job_meta_data["excludeVmTagIds"]
        ):
            msg = "Job '%s' is already updated, skipping." % module.params.get("name")
            if module.check_mode:
                msg = "Check Mode: " + msg
            module.exit_json(
                msg=msg,
                changed=False,
            )
        if not job_meta_data["sourceIds"] and not job_meta_data["vmTagIds"]:
            msg = "Please specify one or more sources to backup. Provided VMs are not available"
            if module.check_mode:
                msg = "Check Mode: " + msg
            module.exit_json(
                msg=msg,
                changed=False,
            )
        if module.check_mode:
            results = dict(
                changed=True, msg="Check Mode: Successfully updated the protection job"
            )
        else:
            response = update_job(module, job_meta_data, "")
            results = dict(
                changed=True, msg="Successfully updated the protection job", **response
            )
        module.exit_json(**results)
    else:
        msg = "The protection job already exists"
        msg = "Check Mode: " + msg
        module.exit_json(
            msg=msg,
            id=job_meta_data["id"],
            name=module.params.get("name"),
            changed=False,
        )


def delete_sources(module, job_meta_data, job_details):
    missing_sources = []
    try:
        if module.params.get("environment") == "PhysicalFiles":
            job_details["environment"] = "Physical"
        for source in module.params.get("protection_sources"):
            job_details["endpoint"] = source["endpoint"]
            source_id = get__prot_source_id__by_endpoint(module, job_details)
            if source_id in job_meta_data["sourceIds"]:
                job_meta_data["sourceIds"].remove(source_id)
            else:
                missing_sources.append(source["endpoint"])
            if module.params.get("environment") == "PhysicalFiles":
                for source in job_meta_data["sourceSpecialParameters"]:
                    if source["sourceId"] == source_id:
                        index = job_meta_data["sourceSpecialParameters"].index(source)
                        del job_meta_data["sourceSpecialParameters"][index]
        if len(job_meta_data["sourceIds"]) == 0:
            msg = "Cannot remove all the sources from a protection job."
            if module.check_mode:
                msg = "Check Mode: " + msg
            module.fail_json(
                msg=msg,
                id=job_meta_data["id"],
                changed=False,
                name=module.params.get("name"),
            )
        if missing_sources:
            # If any source provided is not available in the job, sources are
            # not updated.
            msg = (
                "Removing sources from protection job failed. Following list "
                "of source(s) are not available in the job: %s"
                % ", ".join(missing_sources)
            )
            if module.check_mode:
                msg = "Check Mode: " + msg
            module.fail_json(
                msg=msg,
                id=job_meta_data["id"],
                changed=False,
                name=module.params.get("name"),
            )
        job_meta_data["token"] = job_details["token"]
        if module.check_mode:
            module.exit_json(
                changed=True,
                msg="Check Mode: Successfully removed sources from the protection job",
            )
        response = update_job(module, job_meta_data)
        module.exit_json(
            changed=True,
            msg="Successfully removed sources from the protection job",
            **response
        )
    except Exception:
        module.fail_json(
            changed=False, msg="Error while removing sources from the protection job"
        )


def update_job_util(module, job_details, job_exists):
    if (
        len(module.params.get("protection_sources")) == 1
        and not module.params.get("protection_sources")[0]
    ):
        module.fail_json(
            msg="Missing protection sources to add to the existing protection job",
            id=job_exists,
            name=module.params.get("name"),
        )

    job_details["id"] = job_exists
    job_details["sourceIds"] = list()
    if job_details["environment"] == "PhysicalFiles":
        job_details["environment"] = "Physical"
    prot_source = dict(
        environment=job_details["environment"], token=job_details["token"]
    )
    i = 0
    for source in module.params.get("protection_sources"):
        prot_source["endpoint"] = source["endpoint"]
        source_id = get__prot_source_id__by_endpoint(module, prot_source)
        if source_id:
            job_details["sourceIds"].append(source_id)
            module.params.get("protection_sources")[i]["endpoint"] = source_id
        else:
            module.params.get("protection_sources")[i]["endpoint"] = None
        i += 1
    job_details["parentSourceId"] = get__prot_source_root_id__by_environment(
        module, job_details
    )
    job_details["environment"] = module.params.get("environment")
    existing_job_details = get_prot_job_details(job_details, module)
    already_exist_in_job = set(job_details["sourceIds"]).issubset(
        existing_job_details["sourceIds"]
    )

    update_sources = []
    is_indexing_updated = False
    indexing_policy = existing_job_details["indexingPolicy"]
    indexing = module.params.get("indexing", {})
    allow_prefixes = ["/"]
    deny_prefixes = [
        "/$Recycle.Bin",
        "/Windows",
        "/Program Files",
        "/Program Files (x86)",
        "/ProgramData",
        "/System Volume Information",
        "/Users/*/AppData",
        "/Recovery",
        "/var",
        "/usr",
        "/sys",
        "/proc",
        "/lib",
        "/grub",
        "/grub2",
        "/opt",
        "/splunk",
    ]

    if module.params.get("disable_indexing") is False:
        if (
            set(indexing.get("allowed_prefix", allow_prefixes))
            != set(indexing_policy.get("allowPrefixes", []))
        ) or (
            set(indexing.get("denied_prefix", deny_prefixes))
            != set(indexing_policy.get("denyPrefixes", []))
        ):
            update_indexing(module, existing_job_details)
            is_indexing_updated = True
    if indexing_policy["disableIndexing"] != module.params.get("disable_indexing"):
        update_indexing(module, existing_job_details)
        is_indexing_updated = True
    if job_details["environment"] == "PhysicalFiles":
        existing_file_path = defaultdict(dict)
        # Fetch existing include exclude path details.
        for each_source in existing_job_details["sourceSpecialParameters"]:
            source_id = each_source["sourceId"]
            existing_file_path[source_id] = {
                _params["backupFilePath"]: _params.get("excludedFilePaths", [])
                for _params in each_source["physicalSpecialParameters"]["filePaths"]
            }
        for source in module.params.get("protection_sources"):
            source_id = source["endpoint"]
            # Check the source is already available in the job.
            if source_id not in list(existing_file_path.keys()):
                continue
            paths = source.get("paths", [])
            if not paths:
                update_sources.append(source_id)
                continue
            for path in paths:
                include_path = path.get("includeFilePath", "")
                exclude_path = path.get("excludeFilePaths", [])

                # Check whether the include path is already available.
                if include_path not in list(existing_file_path[source_id].keys()):
                    update_sources.append(source_id)
                    break

                # Check if existing excluded path matches with new exclude path.
                if sorted(exclude_path) != sorted(
                    existing_file_path[source_id][include_path]
                ):
                    update_sources.append(source_id)
                    break
    if update_sources:
        already_exist_in_job = False

    # Check default fields are updated.
    update_default_fields = check_default_fields(
        module, existing_job_details, job_details
    )
    if (
        not update_default_fields
        and not is_indexing_updated
        and already_exist_in_job
        and len(job_details["sourceIds"]) != 0
    ):
        msg = "The protection sources are already being protected"
        if module.check_mode:
            msg = "Check Mode: " + msg
        results = dict(
            changed=False,
            msg=msg,
            id=job_exists,
            name=module.params.get("name"),
        )
        module.exit_json(**results)
    elif (
        is_indexing_updated
        or update_default_fields
        or (not already_exist_in_job and len(job_details["sourceIds"]) != 0)
    ):
        indexing_msg = ""
        new_sources = list(
            set(job_details["sourceIds"]).difference(existing_job_details["sourceIds"])
        )
        if update_sources:
            # Add sources with updated paths to new sources.
            new_sources.extend(update_sources)
            [
                existing_job_details["sourceIds"].remove(_id)
                for _id in new_sources
                if _id in existing_job_details["sourceIds"]
            ]
        existing_job_details["sourceIds"].extend(new_sources)
        existing_job_details["token"] = job_details["token"]
        if is_indexing_updated:
            indexing_msg = "indexing policies, "
        if not module.check_mode:
            update_job(module, existing_job_details, new_sources)
        if job_details["environment"] == "PhysicalFiles":
            msg = indexing_msg + "sources and filepaths to existing protection job"
        else:
            msg = indexing_msg + "sources to existing protection job"
        if module.check_mode:
            results = dict(
                changed=True, msg="Check Mode: This action will update " + msg
            )
        else:
            results = dict(changed=True, msg="Successfully updated " + msg)
    else:
        module.fail_json(
            msg="Sources don't exist on the cluster",
            id=job_exists,
            name=module.params.get("name"),
        )
    module.exit_json(**results)


def main():
    # => Load the default arguments including those specific to the Cohesity Protection Jobs.
    argument_spec = cohesity_common_argument_spec()
    argument_spec.update(
        dict(
            state=dict(
                choices=["present", "absent", "started", "stopped"], default="present"
            ),
            name=dict(type="str", required=True, aliases=["job_name"]),
            description=dict(type="str", default=""),
            # => Currently, the only supported environments types are list in the choices
            # => For future enhancements, the below list should be consulted.
            # => 'SQL', 'View', 'Puppeteer', 'Pure', 'Netapp', 'HyperV', 'Acropolis', 'Azure'
            environment=dict(
                choices=["VMware", "PhysicalFiles", "Physical", "GenericNas", "View"],
                default="PhysicalFiles",
            ),
            view_name=dict(type="str", required=False),
            protection_sources=dict(
                type="list", aliases=["sources"], default=[], elements="dict"
            ),
            protection_policy=dict(type="str", aliases=["policy"], default="Bronze"),
            storage_domain=dict(type="str", default="DefaultStorageDomain"),
            delete_sources=dict(type="bool", default=False),
            delete_vms=dict(type="list", elements="str"),
            time_zone=dict(type="str", default="America/Los_Angeles"),
            start_time=dict(type="str", default=""),
            delete_backups=dict(type="bool", default=False),
            ondemand_run_type=dict(
                choices=["Regular", "Full", "Log", "System"], default="Regular"
            ),
            cancel_active=dict(type="bool", default=False),
            validate_certs=dict(type="bool", default=False, aliases=["cohesity_validate_certs"]),
            append_to_existing=dict(type="bool", default=False),
            exclude=dict(type="list", default=[], elements="str"),
            include=dict(type="list", default=[], elements="str"),
            exclude_tags=dict(type="list", default=[], elements="dict"),
            include_tags=dict(type="list", default=[], elements="dict"),
            disable_indexing=dict(type="bool", default=False),
            indexing=dict(type="dict", default={}),
        )
    )

    # => Create a new module object
    module = AnsibleModule(argument_spec=argument_spec, supports_check_mode=True)
    global client
    client = get_cohesity_client(module)
    results = dict(
        changed=False,
        msg="Attempting to manage Protection Source",
        state=module.params.get("state"),
    )

    job_details = dict(
        token=get__cohesity_auth__token(module),
        name=module.params.get("name"),
        description=module.params.get("description"),
        environment=module.params.get("environment"),
        sourceIds=module.params.get("protection_sources"),
        policyId=module.params.get("protection_policy"),
        viewBoxId=module.params.get("storage_domain"),
        timezone=module.params.get("time_zone"),
    )

    job_exists, job_meta_data = check__protection_job__exists(module, job_details)
    prot_source = dict(
        environment=job_details["environment"], token=job_details["token"]
    )

    if module.check_mode and (
        module.params.get("state") == "absent"
        or (module.params.get("state") == "present" and not job_exists)
    ):
        ERROR_LIST = []
        check_mode_results = dict(
            changed=False,
            msg="Check Mode: Cohesity Protection Job is not currently registered",
            id="",
        )
        if module.params.get("state") == "present":
            check_mode_results["id"] = job_exists
            for source in module.params.get("protection_sources"):
                # Check whether the source is already registered or not.
                prot_source["endpoint"] = source["endpoint"]
                if job_details["environment"] == "PhysicalFiles":
                    prot_source["environment"] = "Physical"
                source_id = get__prot_source_id__by_endpoint(module, prot_source)
                if not source_id:
                    ERROR_LIST.append(
                        "Protection Source '%s' is not registered in the cluster."
                        % source["endpoint"]
                    )
                if job_details["environment"] in ["Physical", "PhysicalFiles"]:
                    # Check all the endpoints are reachable.
                    status = check_source_reachability(source["endpoint"])
                    if not status:
                        ERROR_LIST.append(
                            "Please ensure cohesity agent is installed in the source '%s' and port 50051 is open."
                            % source["endpoint"]
                        )
            if not get__prot_policy_id__by_name(module, job_details):
                ERROR_LIST.append(
                    "Protection policy '%s' is not available in the cluster."
                    % job_details["policyId"]
                )
            if not get__storage_domain_id__by_name(module, job_details):
                ERROR_LIST.append(
                    "Storage domain '%s' is not available in the cluster."
                    % job_details["viewBoxId"]
                )
            if ERROR_LIST:
                check_mode_results["ERROR_LIST"] = ERROR_LIST
                check_mode_results[
                    "msg"
                ] = "Check Mode: Cohesity Protection Job is not currently registered. Please fix the list of errors to register the Cohesity Protection Job."
            else:
                check_mode_results[
                    "msg"
                ] = "Check Mode: Cohesity Protection Job is not currently registered.  This action would register the Cohesity Protection Job."

        else:
            if job_exists:
                check_mode_results[
                    "msg"
                ] = "Check Mode: Cohesity Protection Job is currently registered.  This action would unregister the Cohesity Protection Job."
                check_mode_results["id"] = job_exists
            else:
                check_mode_results[
                    "msg"
                ] = "Check Mode: Cohesity Protection Job is not currently registered.  No changes."
        module.exit_json(**check_mode_results)

    elif module.params.get("state") == "present":
        results["source_vars"] = job_details
        if job_exists:
            if module.params.get("environment") == "VMware":
                update_vmware_job(module, job_meta_data, job_details)
            if module.params.get("environment") in (
                "PhysicalFiles",
                "Physical",
                "GenericNas",
            ):
                if module.params.get("delete_sources") is True:
                    delete_sources(module, job_meta_data, job_details)
                else:
                    update_job_util(module, job_details, job_exists)
            else:
                module.exit_json(
                    msg="The protection job already exists",
                    id=job_exists,
                    name=module.params.get("name"),
                    changed=False,
                )

        else:
            check__mandatory__params(module)
            if job_details["environment"] == "View":
                job_details["viewName"] = module.params.get("view_name")
                job_details["viewBoxId"] = get_view_storage_domain_id(
                    module, job_details
                )
                del job_details["sourceIds"]
            else:
                job_details["sourceIds"] = list()
                if job_details["environment"] == "PhysicalFiles":
                    job_details["environment"] = "Physical"
                i = 0
                for source in module.params.get("protection_sources"):
                    job_details["endpoint"] = source["endpoint"]
                    source_id = get__prot_source_id__by_endpoint(module, job_details)
                    if source_id:
                        job_details["sourceIds"].append(source_id)
                        module.params.get("protection_sources")[i][
                            "endpoint"
                        ] = source_id
                    else:
                        module.params.get("protection_sources")[i]["endpoint"] = None
                    i += 1
                job_details[
                    "parentSourceId"
                ] = get__prot_source_root_id__by_environment(module, job_details)
                if job_details["environment"] == "VMware":
                    job_details["parentSourceId"] = source_id
                job_details["viewBoxId"] = get__storage_domain_id__by_name(
                    module, job_details
                )
            job_details["environment"] = module.params.get("environment")
            job_details["policyId"] = get__prot_policy_id__by_name(module, job_details)
            if module.params.get("start_time"):
                start_time = module.params.get("start_time").replace(":", "")
                if not len(start_time) == 4:
                    # => There are only so many options here but if we get more characters
                    # => than four then we need to escape quickly.
                    module.fail_json(
                        msg="Invalid start_time selected ("
                        + module.params.get("start_time")
                        + ").  Please review and submit the correct Protection Job Starting time."
                    )
                job_details["startTime"] = dict(
                    hour=int(start_time[0] + start_time[1]),
                    minute=int(start_time[2] + start_time[3]),
                )

            response = register_job(module, job_details)

            results = dict(
                changed=True,
                msg="Registration of Cohesity Protection Job Complete",
                **response
            )

    elif module.params.get("state") == "absent":
        if job_exists:
            # If protection sources list is not provided, remove the job and
            # snapshot. If sources are provided remove only specified sources
            # from the job.
            job_details["id"] = job_exists
            job_details["deleteSnapshots"] = module.params.get("delete_backups")

            # If the job is running, stop the job and delete the job.
            job_details["active_only"] = True
            job_details["is_deleted"] = False
            currently_active = get__protection_run__all__by_id(module, job_details)
            if currently_active:
                stop_job(module, job_details)
                time.sleep(10)
            response = unregister_job(module, job_details)

            results = dict(
                changed=True,
                msg="Unregistration of Cohesity Protection Job Complete",
                id=job_exists,
                name=module.params.get("name"),
            )
        else:
            results = dict(
                changed=False,
                msg="The Protection Job for this host is currently not registered",
                name=module.params.get("name"),
            )

    elif module.params.get("state") == "started":
        if job_exists:
            job_details["id"] = job_exists
            job_details["sourceIds"] = []
            job_details["runType"] = module.params.get("ondemand_run_type")

            if module.params.get("environment") == "VMware":
                ids = []
                job_meta_data = {"parentSourceId": job_meta_data["parentSourceId"]}
                if len(module.params.get("include")) != 0:
                    vms = module.params.get("include")
                    ids = get_vmware_ids(module, job_meta_data, job_details, vms)
                job_details["sourceIds"] = ids
            elif "Physical" in module.params.get("environment"):
                prot_source["environment"] = "Physical"
                for source in module.params.get("protection_sources"):
                    if source and isinstance(source, dict):
                        prot_source["endpoint"] = source["endpoint"]
                        source_id = get__prot_source_id__by_endpoint(
                            module, prot_source
                        )
                        if source_id:
                            job_details["sourceIds"].append(source_id)
            response = start_job(module, job_details)

            results = dict(
                changed=True,
                msg="The Protection Job for this host has been started",
                id=job_exists,
                name=module.params.get("name"),
            )
        else:
            results = dict(
                changed=False,
                msg="The Protection Job for this host is currently not registered",
                name=module.params.get("name"),
            )

    elif module.params.get("state") == "stopped":
        if job_exists:
            job_details["id"] = job_exists

            response = stop_job(module, job_details)

            results = dict(
                changed=True,
                msg="The Protection Job for this host has been stopped",
                id=job_exists,
                name=module.params.get("name"),
            )
        else:
            results = dict(
                changed=False,
                msg="The Protection Job for this host is currently not registered",
                name=module.params.get("name"),
            )
    else:
        # => This error should never happen based on the set assigned to the parameter.
        # => However, in case, we should raise an appropriate error.
        module.fail_json(
            msg="Invalid State selected: {0}".format(module.params.get("state")),
            changed=False,
        )
    if module.check_mode:
        if "Check Mode" not in results["msg"]:
            results["msg"] = "Check Mode: " + results["msg"]
    module.exit_json(**results)


if __name__ == "__main__":
    main()
